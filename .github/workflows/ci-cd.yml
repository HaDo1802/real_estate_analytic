name: Real Estate ETL Pipeline CI/CD

on:
  schedule:
    - cron: "0 6 * * *" # Daily at 6 AM UTC
  push:
    branches:
      - main

  pull_request:
    branches:
      - main

  workflow_dispatch:
    inputs:
      run_full_pipeline:
        description: "Run full ETL pipeline (not just tests)"
        required: false
        default: "false"
        type: choice
        options:
          - "true"
          - "false"

env:
  PYTHON_VERSION: "3.9"

jobs:
  format-and-lint:
    name: Code Format & Lint
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install formatting tools
        run: |
          python -m pip install --upgrade pip
          pip install black isort flake8

      - name: Format code with Black
        run: |
          echo "ğŸ¨ Formatting code with Black..."
          black etl/ tests/ --line-length 127

      - name: Sort imports with isort
        run: |
          echo "ğŸ“¦ Sorting imports..."
          isort etl/ tests/ --profile black

      - name: Lint with flake8
        run: |
          echo "ğŸ” Linting with flake8..."
          flake8 etl/ tests/ --max-line-length=127 --exit-zero

      - name: Commit and push formatting changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          if ! git diff --quiet; then
            echo "âœ¨ Changes detected, committing..."
            git add -A
            git commit -m "refactor: auto-format code with Black and isort"
            git push
            echo "âœ… Formatting pushed"
          else
            echo "âœ… Code already formatted"
          fi
  unit-test:
    name: Run Unit Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install pandas pytest
      
      - name: Run unit tests
        run: |
          pytest tests/test_*.py -v
      
      - name: Tests passed!
        run: echo "âœ… All tests passed!"
  
  docker-build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [unit-test]  # Only run if tests pass
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      # Skip login if running on PR (no secrets available)
      - name: Log in to Docker Hub
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          # Only push if not a PR and secrets exist
          push: ${{ github.event_name != 'pull_request' && secrets.DOCKER_USERNAME != '' }}
          tags: ${{ secrets.DOCKER_USERNAME }}/real-estate-etl:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

  run-etl-pipeline:
    name: Execute ETL Pipeline
    runs-on: ubuntu-latest
    needs: [format-and-lint, unit-test, docker-build]

    if: |
      github.ref == 'refs/heads/main' && 
      (github.event_name == 'schedule' || 
       (github.event_name == 'workflow_dispatch' && 
        github.event.inputs.run_full_pipeline == 'true'))

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create data directories
        run: |
          mkdir -p data/raw data/transformed etl_log

      - name: Configure environment
        run: |
          echo "RAPID_API_KEY=${{ secrets.RAPID_API_KEY }}" > .env
          echo "POSTGRES_HOST=${{ secrets.POSTGRES_HOST }}" >> .env
          echo "POSTGRES_DB=${{ secrets.POSTGRES_DB }}" >> .env
          echo "POSTGRES_USER=${{ secrets.POSTGRES_USER }}" >> .env
          echo "POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}" >> .env
          echo "POSTGRES_PORT=${{ secrets.POSTGRES_PORT }}" >> .env

      - name: Extract Data
        run: |
          echo "ğŸ•·ï¸ Extracting data from Zillow..."
          cd etl
          python extract.py

      - name: Transform Data
        run: |
          echo "ğŸ§¹ Transforming data..."
          cd etl
          python transform.py

      - name: Load to Database
        run: |
          echo "ğŸ—„ï¸ Loading to PostgreSQL..."
          cd etl
          python load.py
          echo "âœ… Load completed"

      - name: Pipeline Summary
        run: |
          echo "ğŸ‰ ETL Pipeline Completed!"
          echo "âœ… Extract â†’ Transform â†’ Load"
